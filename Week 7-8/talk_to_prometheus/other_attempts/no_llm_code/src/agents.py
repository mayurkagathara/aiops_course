# Agents: PlanningAgent, ExecutorAgent, AnalyzerAgent
import time
from typing import List, Dict, Any
import config, utils, tools, schemas

class PlanningAgent:
    def make_plan(self, user_query: str) -> schemas.Plan:
        now = utils.now_seconds()
        q = user_query.lower()
        if "memory" in q or "mem" in q:
            prom = 'node_memory_MemAvailable_bytes{job="node-exporter"}'
            endpoint = "query_range"
        elif "cpu" in q:
            prom = 'avg by (instance) (irate(node_cpu_seconds_total{job="node-exporter",mode!="idle"}[5m]))'
            endpoint = "query_range"
        else:
            prom = 'up'
            endpoint = "query"
        start = now - 15 * 60
        end = now
        step = 15
        item = schemas.PlanItem(
            endpoint=endpoint,
            promql=utils.simple_promql_sanitize(prom),
            params=schemas.QueryParams(start=start, end=end, step=step),
            purpose="auto-generated",
            expected_size="small"
        )
        plan = schemas.Plan(user_intent=user_query, items=[item], notes="generated by PlanningAgent")
        return plan

class ExecutorAgent:
    def __init__(self):
        self.prom = tools.PrometheusTool()
        self.store = tools.FileStoreTool(path=config.DATA_FILE_PATH)
        self.memory: Dict[str, Any] = {}

    def execute(self, plan: schemas.Plan) -> schemas.ExecResult:
        results: List[schemas.ExecItemResult] = []
        ts = int(time.time())
        for idx, item in enumerate(plan.items):
            try:
                if item.endpoint == "query_range":
                    resp = self.prom.query_range(item.promql, item.params.start, item.params.end, item.params.step)
                else:
                    resp = self.prom.query(item.promql)
                approx = utils.estimate_size_bytes(resp)
                key = f"exec/{ts}/{idx}"
                if approx > config.INMEMORY_MAX_BYTES:
                    self.store.write(key, resp, comment=f"Stored by ExecutorAgent at {ts}")
                    data_ref = schemas.DataRef(storage="file", key=key, approx_bytes=approx)
                else:
                    self.memory[key] = resp
                    data_ref = schemas.DataRef(storage="memory", key=key, approx_bytes=approx)
                results.append(schemas.ExecItemResult(
                    plan_index=idx,
                    promql=item.promql,
                    endpoint=item.endpoint,
                    status="ok",
                    data_ref=data_ref
                ))
            except Exception as e:
                results.append(schemas.ExecItemResult(
                    plan_index=idx,
                    promql=item.promql,
                    endpoint=item.endpoint,
                    status="error",
                    error=str(e),
                    data_ref=None
                ))
        return schemas.ExecResult(results=results, __comments="Execution finished")

class AnalyzerAgent:
    def __init__(self, executor: ExecutorAgent):
        self.executor = executor
        self.runner = tools.PythonRunnerTool()

    def analyze(self, exec_result: schemas.ExecResult) -> schemas.Analysis:
        import numpy as np
        summary_stats = {}
        findings = []
        recommendations = []
        next_q = []
        for item in exec_result.results:
            dr = item.data_ref
            if not dr:
                continue
            if dr.storage == "memory":
                payload = self.executor.memory.get(dr.key)
                series = payload.get("data", {}).get("result", [])
                for s in series:
                    metric = s.get("metric", {})
                    name = metric.get("__name__", "series")
                    values = [float(v[1]) for v in s.get("values", [])] if s.get("values") else []
                    if not values:
                        continue
                    arr = np.array(values)
                    summary_stats[name] = {
                        "min": float(arr.min()),
                        "max": float(arr.max()),
                        "mean": float(arr.mean()),
                        "p50": float(np.percentile(arr,50)),
                        "p95": float(np.percentile(arr,95)),
                        "count": int(arr.size)
                    }
                findings.append(schemas.Finding(title="Memory-result summary", detail="Computed quick stats", severity="info", evidence={}))
            else:
                res = self.runner.run_job({"key": dr.key})
                if res.get("error"):
                    findings.append(schemas.Finding(title="Analysis runner failed", detail=str(res), severity="low"))
                else:
                    summary_stats.update(res.get("summary", {}))
                    findings.append(schemas.Finding(title="File-analysis completed", detail="Used analysis-runner", severity="info"))
        if not findings:
            findings.append(schemas.Finding(title="No data found", detail="No series returned", severity="info"))
        recommendations.append(schemas.Recommendation(text="If results are large, consider narrowing time window."))

        ms = schemas.MetricsSummary(series_count=len(summary_stats), stats=summary_stats)
        analysis = schemas.Analysis(summary=ms, findings=findings, recommendations=recommendations, next_questions=next_q)
        return analysis
