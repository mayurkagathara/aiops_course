input {
  file {
    path => "/var/log/ingest/app.log"
    start_position => "beginning"
    sincedb_path => "/var/log/ingest/app.sincedb"
    mode => "tail"
    discover_interval => "5"
    stat_interval => "1"
    codec => plain { charset => "UTF-8" }
  }
}

filter {
  # Parse the line using GROK
  grok {
    match => {
      "message" => [
        # Example:
        # 2025-07-22 07:46:57,462 INFO [payment-service] (customer=cust001, customer_name=Acme Corp, environment=prod, log_type=app) Request to /data completed in 133ms
        "%{TIMESTAMP_ISO8601:ts} %{LOGLEVEL:log_level} \[%{DATA:application_name}\] \(customer=%{WORD:customer}, customer_name=%{DATA:customer_name}, environment=%{WORD:environment_name}, log_type=%{WORD:log_type}\) %{GREEDYDATA:msg}"
      ]
    }
    overwrite => [ "message" ]
  }

  # Move parsed msg to message field
  mutate {
    rename => { "msg" => "message" }
  }

  # Normalize types/whitespace
  mutate {
    strip => ["customer_name", "message"]
  }

  # Convert timestamp string to @timestamp
  date {
    match => ["ts", "YYYY-MM-dd HH:mm:ss,SSS"]
    target => "@timestamp"
    timezone => "UTC"
  }
  mutate {
    # Remove fields that aren't in our template
    remove_field => ["ts", "host", "path", "@version", "event", "log"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logs-aiops_demo"
    # Install index template to enforce types
    template => "/usr/share/logstash/templates/logs-template.json"
    template_name => "logs-template"
    template_overwrite => true
  }
  stdout { codec => rubydebug }
}
